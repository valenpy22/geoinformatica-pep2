{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57207de3-dd37-4a71-b169-79d91ed9b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ðŸŒ Template PEP1 Configurado Exitosamente ===\n",
      "ðŸ“‚ Base Dir       : /home/jovyan\n",
      "ðŸ’¾ GeoDatabase    : âœ… Encontrada\n",
      "ðŸ“Š Censo CSV      : âœ… Encontrado\n",
      "=================================================\n",
      "ðŸš€ Iniciando SÃ­ntesis (Notebook 05)\n",
      "ðŸ—ºï¸ Base de mapas cargada: 52 comunas (deben ser 52)\n",
      "ðŸ”„ Procesando datos de accesibilidad...\n",
      "ðŸ“Š Dimensiones Finales: (52, 2)\n",
      "   (DeberÃ­a ser 52 filas. Las faltantes tendrÃ¡n NaN y serÃ¡n imputadas despuÃ©s)\n",
      "ðŸ§© Servicios detectados (0): []\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1: SETUP Y CARGA DE DATOS (CORREGIDA V3 - 52 COMUNAS)\n",
    "# ============================================================================\n",
    "%run ./00_template.py\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "# Definir capa de comunas\n",
    "LAYER_COMUNAS = \"comunas_rm_censo\" \n",
    "\n",
    "# Rutas\n",
    "PARQ = OUTPUTS_DIR / \"comunas_accessibility_otp.parquet\"\n",
    "LONG = OUTPUTS_DIR / \"accesibilidad_otp_final.csv\" # Usamos el final\n",
    "\n",
    "print(\"ðŸš€ Iniciando SÃ­ntesis (Notebook 05)\")\n",
    "\n",
    "# --- 1. Cargar GeometrÃ­a (La Verdad Oficial: 52 Comunas) ---\n",
    "comunas = gpd.read_file(RUTA_GPKG, layer=LAYER_COMUNAS).copy()\n",
    "if \"CUT_COM\" in comunas.columns and \"cod_comuna\" not in comunas.columns:\n",
    "    comunas = comunas.rename(columns={\"CUT_COM\": \"cod_comuna\"})\n",
    "comunas[\"cod_comuna\"] = comunas[\"cod_comuna\"].astype(str)\n",
    "\n",
    "print(f\"ðŸ—ºï¸ Base de mapas cargada: {len(comunas)} comunas (deben ser 52)\")\n",
    "\n",
    "# --- 2. Cargar y Procesar CSV ---\n",
    "# Siempre reconstruimos para asegurar el cruce correcto\n",
    "print(\"ðŸ”„ Procesando datos de accesibilidad...\")\n",
    "\n",
    "if not LONG.exists():\n",
    "    # Fallback\n",
    "    LONG = OUTPUTS_DIR / \"acc_long_partial.csv\"\n",
    "\n",
    "if not LONG.exists():\n",
    "    raise FileNotFoundError(\"âŒ No se encuentra ningÃºn CSV de datos.\")\n",
    "\n",
    "acc_long = pd.read_csv(LONG)\n",
    "\n",
    "# NormalizaciÃ³n de nombres de columnas\n",
    "if \"minutos\" in acc_long.columns: acc_long = acc_long.rename(columns={\"minutos\": \"t_min_otp\"})\n",
    "if \"time\" in acc_long.columns: acc_long = acc_long.rename(columns={\"time\": \"t_min_otp\"})\n",
    "if \"cat\" in acc_long.columns: acc_long = acc_long.rename(columns={\"cat\": \"categoria\"})\n",
    "if \"cod\" in acc_long.columns: acc_long = acc_long.rename(columns={\"cod\": \"cod_comuna\"})\n",
    "\n",
    "# Asegurar numÃ©rico\n",
    "acc_long[\"t_min_otp\"] = pd.to_numeric(acc_long[\"t_min_otp\"], errors=\"coerce\")\n",
    "\n",
    "# Pivotar\n",
    "acc_pivot = acc_long.pivot_table(\n",
    "    index=[\"cod_comuna\"], \n",
    "    columns=\"categoria\",\n",
    "    values=\"t_min_otp\",\n",
    "    aggfunc=\"min\"\n",
    ").reset_index()\n",
    "\n",
    "acc_pivot[\"cod_comuna\"] = acc_pivot[\"cod_comuna\"].astype(str)\n",
    "\n",
    "# --- 3. EL CRUCE MAESTRO (FIX: Left Join usando Comunas como base) ---\n",
    "# Usamos 'comunas' a la izquierda para mantener las 52 filas, aunque no tengan datos.\n",
    "base_comunas = comunas[[\"cod_comuna\", \"COMUNA\"]].copy()\n",
    "acc = base_comunas.merge(acc_pivot, on=\"cod_comuna\", how=\"left\")\n",
    "\n",
    "acc = acc.rename(columns={\"COMUNA\": \"comuna\"})\n",
    "\n",
    "# Guardar\n",
    "acc.to_parquet(PARQ, index=False)\n",
    "\n",
    "# Definir Features\n",
    "id_cols = {\"cod_comuna\", \"comuna\", \"cluster\", \"geometry\"} \n",
    "FEATURES = [c for c in acc.columns if c not in id_cols]\n",
    "\n",
    "print(f\"ðŸ“Š Dimensiones Finales: {acc.shape}\")\n",
    "print(f\"   (DeberÃ­a ser 52 filas. Las faltantes tendrÃ¡n NaN y serÃ¡n imputadas despuÃ©s)\")\n",
    "print(f\"ðŸ§© Servicios detectados ({len(FEATURES)}): {FEATURES}\")\n",
    "\n",
    "if len(acc) != 52:\n",
    "    print(\"âš ï¸ ADVERTENCIA: AÃºn no tenemos 52 filas. Revisa el GeoPackage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88177ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     X[col] \u001b[38;5;241m=\u001b[39m X[col]\u001b[38;5;241m.\u001b[39mfillna(p90)\n\u001b[1;32m     14\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 15\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# --- 2. Clustering (Usamos K=4 basado en anÃ¡lisis previo) ---\u001b[39;00m\n\u001b[1;32m     18\u001b[0m k_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m \n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:839\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:875\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \n\u001b[1;32m    845\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    874\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:795\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    791\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    792\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    793\u001b[0m )\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 795\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 2, 3 y 4: CLUSTERING Y CÃLCULO DE DESIERTOS\n",
    "# ============================================================================\n",
    "\n",
    "# --- 1. Preprocesamiento ---\n",
    "X = acc[FEATURES].copy()\n",
    "\n",
    "# ImputaciÃ³n: Si OTP fallÃ³ (NaN), asumimos que es porque estÃ¡ muy lejos.\n",
    "# Rellenamos con el percentil 90 (tiempo alto = \"castigo\")\n",
    "for col in FEATURES:\n",
    "    p90 = np.nanpercentile(X[col].values, 90)\n",
    "    X[col] = X[col].fillna(p90)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 2. Clustering (Usamos K=4 basado en anÃ¡lisis previo) ---\n",
    "k_opt = 4 \n",
    "kmeans = KMeans(n_clusters=k_opt, random_state=42, n_init=10)\n",
    "\n",
    "df = acc.copy()\n",
    "df[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# --- 3. DetecciÃ³n de Desiertos ---\n",
    "THRESH_MIN = 30.0  # Umbral crÃ­tico: mÃ¡s de 30 min se considera desierto\n",
    "\n",
    "tabla = df.copy()\n",
    "\n",
    "# Creamos flags binarios (1 = Es desierto, 0 = No)\n",
    "for col in FEATURES:\n",
    "    # Es desierto si es NaN (sin cobertura) o si el tiempo > umbral\n",
    "    tabla[f\"es_desierto_{col}\"] = (tabla[col].isna()) | (tabla[col] > THRESH_MIN)\n",
    "\n",
    "# Contamos cuÃ¡ntos servicios fallan por comuna\n",
    "bin_cols = [c for c in tabla.columns if c.startswith(\"es_desierto_\")]\n",
    "tabla[\"n_servicios_en_desierto\"] = tabla[bin_cols].sum(axis=1)\n",
    "tabla[\"porcentaje_desierto\"] = (tabla[\"n_servicios_en_desierto\"] / len(FEATURES)) * 100\n",
    "\n",
    "# --- 4. EstadÃ­sticas RÃ¡pidas ---\n",
    "print(f\"--- Resumen de Desiertos (Umbral: {THRESH_MIN} min) ---\")\n",
    "print(f\"Promedio de servicios no accesibles por comuna: {tabla['n_servicios_en_desierto'].mean():.2f}\")\n",
    "print(f\"Peor caso (MÃ¡ximo servicios fallidos): {tabla['n_servicios_en_desierto'].max()} de {len(FEATURES)}\")\n",
    "print(f\"Mejor caso (MÃ­nimo servicios fallidos): {tabla['n_servicios_en_desierto'].min()}\")\n",
    "\n",
    "tabla[[\"cod_comuna\", \"comuna\", \"cluster\", \"n_servicios_en_desierto\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a29ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabla' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# CELDA 5, 6 y 7: VISUALIZACIÃ“N\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 1. Ranking de las peores comunas\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m top_desiertos \u001b[38;5;241m=\u001b[39m \u001b[43mtabla\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcod_comuna\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomuna\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_servicios_en_desierto\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m top_desiertos \u001b[38;5;241m=\u001b[39m top_desiertos\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_servicios_en_desierto\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸš¨ Top 10 Comunas con mayor dÃ©ficit de accesibilidad:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabla' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 5, 6 y 7: VISUALIZACIÃ“N\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Ranking de las peores comunas\n",
    "top_desiertos = tabla[[\"cod_comuna\", \"comuna\", \"cluster\", \"n_servicios_en_desierto\"]].copy()\n",
    "top_desiertos = top_desiertos.sort_values(\"n_servicios_en_desierto\", ascending=False)\n",
    "\n",
    "print(\"ðŸš¨ Top 10 Comunas con mayor dÃ©ficit de accesibilidad:\")\n",
    "display(top_desiertos.head(10))\n",
    "\n",
    "# 2. Mapa de \"Intensidad de Desierto\"\n",
    "comunas_map = comunas.merge(\n",
    "    tabla[[\"cod_comuna\", \"n_servicios_en_desierto\", \"cluster\"]],\n",
    "    on=\"cod_comuna\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.UTM(19, southern_hemisphere=True))\n",
    "comunas_map.plot(\n",
    "    column=\"n_servicios_en_desierto\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    legend_kwds={'label': \"Cantidad de servicios > 30 min\", 'orientation': \"horizontal\"},\n",
    "    cmap=\"Reds\",     # Rojo intenso = Muchos servicios inaccesibles\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=0.3,\n",
    "    missing_kwds={'color': 'lightgrey'}, # Por si alguna comuna no cruzÃ³\n",
    "    transform=ccrs.UTM(19, southern_hemisphere=True)\n",
    ")\n",
    "\n",
    "ax.set_title(f\"Zonas de ExclusiÃ³n: Cantidad de servicios a mÃ¡s de {THRESH_MIN} min\", fontsize=14)\n",
    "ax.set_axis_off()\n",
    "# Agregar elementos del mapa\n",
    "ax.gridlines(draw_labels=True, alpha=0.5)\n",
    "scalebar = ScaleBar(1, location='lower left', scale_loc='bottom', length_fraction=0.1, units='m')\n",
    "ax.add_artist(scalebar)\n",
    "ax.text(0.02, 0.08, 'Datum: WGS84 / UTM 19S', transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax.annotate('N', xy=(0.95, 0.95), xycoords='axes fraction', fontsize=14, ha='center', va='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "ax.arrow(0.95, 0.9, 0, 0.05, head_width=0.01, head_length=0.01, fc='black', ec='black', transform=ax.transAxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "# FunciÃ³n segura para guardar (por si no estÃ¡ definida en template)\n",
    "try:\n",
    "    save_figure(fig, \"sintesis_mapa_indice_desiertos\")\n",
    "except NameError:\n",
    "    plt.savefig(OUTPUTS_DIR / \"sintesis_mapa_indice_desiertos.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 3. GrÃ¡fico de Barras\n",
    "top_plot = top_desiertos.head(15).sort_values(\"n_servicios_en_desierto\") # Top 15 para el grÃ¡fico\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(top_plot[\"comuna\"], top_plot[\"n_servicios_en_desierto\"], color='salmon')\n",
    "ax.set_xlabel(f\"NÃºmero de servicios crÃ­ticos (> {THRESH_MIN} min)\")\n",
    "ax.set_title(\"Ranking de Inaccesibilidad: Las 15 comunas mÃ¡s crÃ­ticas\")\n",
    "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31ac6d-7f7f-407c-bf32-b3f4af72b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 8: EXPORTACIÃ“N\n",
    "# ============================================================================\n",
    "tabla_final_path = OUTPUTS_DIR / \"tabla_final_desiertos_servicios.csv\"\n",
    "tabla.to_csv(tabla_final_path, index=False)\n",
    "\n",
    "print(f\"âœ… AnÃ¡lisis completado.\")\n",
    "print(f\"ðŸ’¾ Archivo maestro guardado en: {tabla_final_path}\")\n",
    "print(\"   Contiene: Tiempos OTP + Cluster asignado + Flags de desierto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
