{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e660634-a078-405e-adea-cb7734a3210b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== üåç Template PEP1 Configurado Exitosamente ===\n",
      "üìÇ Base Dir       : /home/jovyan\n",
      "üíæ GeoDatabase    : ‚úÖ Encontrada\n",
      "üìä Censo CSV      : ‚úÖ Encontrado\n",
      "=================================================\n",
      "üìÇ Carpeta de salida verificada: /home/jovyan/outputs\n",
      "üì° Endpoint OTP: http://otp:8080/routers/default/plan/otp/routers/default/plan\n",
      "üìÖ Fecha simulada: 2023-10-18T08:30:00-03:00\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1: CONFIGURACI√ìN E IMPORTS\n",
    "# ============================================================================\n",
    "%run ./00_template.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "# Configuraci√≥n de Salida\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ Carpeta de salida verificada: {OUTPUTS_DIR}\")\n",
    "\n",
    "# Configuraci√≥n de OTP\n",
    "OTP_HOST = os.getenv(\"OTP_URL\", \"http://otp:8080\").rstrip(\"/\")\n",
    "OTP_URL = f\"{OTP_HOST}/otp/routers/default/plan\"\n",
    "\n",
    "# FECHA CLAVE: Usamos un d√≠a laboral normal (Martes 8:30 AM)\n",
    "# Navidad (25-Dic) tiene frecuencias de feriado, no sirve para evaluar desiertos reales.\n",
    "WHEN_ISO = \"2023-10-18T08:30:00-03:00\"\n",
    "\n",
    "print(f\"üì° Endpoint OTP: {OTP_URL}\")\n",
    "print(f\"üìÖ Fecha simulada: {WHEN_ISO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46889ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Motor OTP configurado: Hora y Modos insertados como texto fijo.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 2: MOTOR DE CONSULTAS OTP (Hora fija insertada como texto)\n",
    "# ============================================================================\n",
    "import requests\n",
    "import time\n",
    "from dateutil import parser as dtparser\n",
    "\n",
    "OTP_URL = \"http://otp:8080/otp/gtfs/v1\"\n",
    "\n",
    "# 1. Quitamos $time de la cabecera\n",
    "# 2. Usamos dos %s: Uno para la hora, otro para los modos\n",
    "PLAN_QUERY = \"\"\"\n",
    "query($oLat: CoordinateValue!, $oLon: CoordinateValue!, $dLat: CoordinateValue!, $dLon: CoordinateValue!) {\n",
    "  planConnection(\n",
    "    origin: { location: { coordinate: { latitude: $oLat, longitude: $oLon } } }\n",
    "    destination: { location: { coordinate: { latitude: $dLat, longitude: $dLon } } }\n",
    "    dateTime: { earliestDeparture: \"%s\" }\n",
    "    modes: {\n",
    "      direct: [WALK]\n",
    "      transit: { transit: [%s] }\n",
    "    }\n",
    "  ) {\n",
    "    edges {\n",
    "      node {\n",
    "        start\n",
    "        end\n",
    "        legs {\n",
    "          mode\n",
    "          duration\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def otp_graphql(query: str, variables: dict, timeout=60, retries=3):\n",
    "    \"\"\"Env√≠a la consulta a OTP.\"\"\"\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.post(OTP_URL, json={\"query\": query, \"variables\": variables}, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if \"errors\" in data:\n",
    "                # Imprimir el mensaje de error para debug\n",
    "                print(f\"‚ö†Ô∏è OTP Error: {data['errors'][0]['message']}\")\n",
    "                return None\n",
    "            return data[\"data\"]\n",
    "        except Exception as e:\n",
    "            if attempt < retries:\n",
    "                time.sleep(0.5)\n",
    "                continue\n",
    "            return None\n",
    "\n",
    "def otp_travel_time_minutes(o_lat, o_lon, d_lat, d_lon, when_iso, modes=[\"BUS\", \"SUBWAY\", \"RAIL\"]):\n",
    "    \"\"\"\n",
    "    Calcula tiempo de viaje.\n",
    "    - Insertamos 'when_iso' y 'modes' directamente en el texto de la query.\n",
    "    - Las coordenadas van como variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Preparar string de modos: \"{ mode: BUS }, { mode: SUBWAY }\"\n",
    "    modes_str = \", \".join([f\"{{ mode: {m} }}\" for m in modes])\n",
    "    \n",
    "    # 2. INYECCI√ìN DE TEXTO (Aqu√≠ estaba el error antes)\n",
    "    # Tenemos dos %s en la query. Pasamos una tupla con (fecha, modos)\n",
    "    final_query = PLAN_QUERY % (when_iso, modes_str)\n",
    "\n",
    "    # 3. Variables (Solo coordenadas, ya no va 'time')\n",
    "    variables = {\n",
    "        \"oLat\": float(o_lat), \"oLon\": float(o_lon),\n",
    "        \"dLat\": float(d_lat), \"dLon\": float(d_lon)\n",
    "    }\n",
    "\n",
    "    # 4. Enviar\n",
    "    data = otp_graphql(final_query, variables)\n",
    "    \n",
    "    if not data or \"planConnection\" not in data:\n",
    "        return None\n",
    "\n",
    "    edges = data[\"planConnection\"][\"edges\"]\n",
    "    if not edges:\n",
    "        return None\n",
    "\n",
    "    best_minutes = float('inf')\n",
    "    found = False\n",
    "    \n",
    "    for e in edges:\n",
    "        node = e[\"node\"]\n",
    "        start = dtparser.isoparse(node[\"start\"])\n",
    "        end = dtparser.isoparse(node[\"end\"])\n",
    "        minutes = (end - start).total_seconds() / 60.0\n",
    "        \n",
    "        if minutes < best_minutes:\n",
    "            best_minutes = minutes\n",
    "            found = True\n",
    "\n",
    "    return best_minutes if found else None\n",
    "\n",
    "print(\"‚úÖ Motor OTP configurado: Hora y Modos insertados como texto fijo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560e117c-4ffd-4ded-828d-cdf1dec68b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cargado Capa 'comunas_rm_censo': 52 registros | CRS: EPSG:32719\n",
      "üìç Puntos de origen/destino preparados: 52 comunas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUT_COM</th>\n",
       "      <th>COMUNA</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13130</td>\n",
       "      <td>San Miguel</td>\n",
       "      <td>-33.499060</td>\n",
       "      <td>-70.651504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13118</td>\n",
       "      <td>Macul</td>\n",
       "      <td>-33.489309</td>\n",
       "      <td>-70.599913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13119</td>\n",
       "      <td>Maip√∫</td>\n",
       "      <td>-33.507027</td>\n",
       "      <td>-70.808888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CUT_COM      COMUNA        lat        lon\n",
       "0    13130  San Miguel -33.499060 -70.651504\n",
       "1    13118       Macul -33.489309 -70.599913\n",
       "2    13119       Maip√∫ -33.507027 -70.808888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 3: PREPARACI√ìN DE PUNTOS (CENTROIDES COMUNALES)\n",
    "# ============================================================================\n",
    "\n",
    "# Cargar comunas\n",
    "gdf_comunas = load_geodata(RUTA_GPKG, layer=\"comunas_rm_censo\")\n",
    "\n",
    "# Asegurar proyecci√≥n Lat/Lon (WGS84) para OTP\n",
    "comunas_wgs = gdf_comunas.to_crs(epsg=4326).copy()\n",
    "\n",
    "# Calcular centroides\n",
    "comunas_wgs[\"centroid\"] = comunas_wgs.geometry.centroid\n",
    "\n",
    "# Definir columnas de ID y Nombre (Basado en Notebook 01/02)\n",
    "ID_COL = \"CUT_COM\" \n",
    "NAME_COL = \"COMUNA\"\n",
    "\n",
    "# Crear tabla limpia de puntos\n",
    "points = comunas_wgs[[ID_COL, NAME_COL, \"centroid\"]].copy()\n",
    "points[\"lat\"] = points[\"centroid\"].y\n",
    "points[\"lon\"] = points[\"centroid\"].x\n",
    "points = points.drop(columns=[\"centroid\"])\n",
    "\n",
    "print(f\"üìç Puntos de origen/destino preparados: {len(points)} comunas.\")\n",
    "display(points.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b4b47d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'origin_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     od_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(CACHE_PATH)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Crear set de pares ya hechos para no repetir (Origen, Destino)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     done_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mod_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, od_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdest_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Cache encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(od_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rutas ya calculadas.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'origin_id'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4: C√ÅLCULO DE MATRIZ DE TIEMPOS (CON CACHE)\n",
    "# ============================================================================\n",
    "\n",
    "CACHE_PATH = OUTPUTS_DIR / \"otp_od_matrix_comunas.csv\"\n",
    "\n",
    "# 1. Cargar Cache si existe\n",
    "if CACHE_PATH.exists():\n",
    "    od_df = pd.read_csv(CACHE_PATH)\n",
    "    # Crear set de pares ya hechos para no repetir (Origen, Destino)\n",
    "    done_pairs = set(zip(od_df[\"origin_id\"], od_df[\"dest_id\"]))\n",
    "    print(f\"‚úÖ Cache encontrado: {len(od_df)} rutas ya calculadas.\")\n",
    "else:\n",
    "    od_df = pd.DataFrame(columns=[\"origin_id\", \"origin_name\", \"dest_id\", \"dest_name\", \"minutes\"])\n",
    "    done_pairs = set()\n",
    "    print(\"üÜï Iniciando c√°lculo desde cero.\")\n",
    "\n",
    "# 2. Convertir a lista de diccionarios para iterar r√°pido\n",
    "rows = points.to_dict(\"records\")\n",
    "\n",
    "# Configuraci√≥n de prueba (Pon None para correr todo)\n",
    "MAX_TEST = None  # Cambia a 5 si quieres probar r√°pido antes de correr todo\n",
    "\n",
    "subset_o = rows[:MAX_TEST] if MAX_TEST else rows\n",
    "subset_d = rows[:MAX_TEST] if MAX_TEST else rows\n",
    "\n",
    "new_records = []\n",
    "save_interval = 20 # Guardar cada 20 consultas\n",
    "\n",
    "print(f\"üöÄ Comenzando c√°lculo para {len(subset_o)} x {len(subset_d)} pares...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, origin in enumerate(subset_o):\n",
    "    for dest in subset_d:\n",
    "        \n",
    "        # Identificador √∫nico del par\n",
    "        pair_key = (origin[ID_COL], dest[ID_COL])\n",
    "        \n",
    "        # Si ya est√° hecho o es el mismo punto, saltar\n",
    "        if pair_key in done_pairs:\n",
    "            continue\n",
    "        \n",
    "        if origin[ID_COL] == dest[ID_COL]:\n",
    "            minutes = 0.0 # Viaje a s√≠ mismo\n",
    "        else:\n",
    "            # CONSULTA A OTP\n",
    "            minutes = otp_travel_time_minutes(\n",
    "                origin[\"lat\"], origin[\"lon\"], \n",
    "                dest[\"lat\"], dest[\"lon\"], \n",
    "                WHEN_ISO\n",
    "            )\n",
    "            \n",
    "            # Feedback visual (print cada cierto tiempo)\n",
    "            print(f\"   Calculando: {origin[NAME_COL]} -> {dest[NAME_COL]} = {minutes if minutes else 'N/A'} min\", end=\"\\r\")\n",
    "\n",
    "        # Agregar a resultados\n",
    "        new_records.append({\n",
    "            \"origin_id\": origin[ID_COL],\n",
    "            \"origin_name\": origin[NAME_COL],\n",
    "            \"dest_id\": dest[ID_COL],\n",
    "            \"dest_name\": dest[NAME_COL],\n",
    "            \"minutes\": minutes\n",
    "        })\n",
    "        done_pairs.add(pair_key)\n",
    "\n",
    "        # Guardado incremental\n",
    "        if len(new_records) >= save_interval:\n",
    "            chunk_df = pd.DataFrame(new_records)\n",
    "            od_df = pd.concat([od_df, chunk_df], ignore_index=True)\n",
    "            od_df.to_csv(CACHE_PATH, index=False)\n",
    "            new_records = [] # Limpiar buffer\n",
    "\n",
    "# Guardado final de remanentes\n",
    "if new_records:\n",
    "    od_df = pd.concat([od_df, pd.DataFrame(new_records)], ignore_index=True)\n",
    "    od_df.to_csv(CACHE_PATH, index=False)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Proceso terminado en {total_time:.1f} segundos.\")\n",
    "print(f\"üíæ Archivo guardado: {CACHE_PATH}\")\n",
    "print(f\"üìä Total pares procesados: {len(od_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73cb05e-8172-49ee-a2eb-a042f247ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 5: CARGA DE SERVICIOS Y CREACI√ìN DE √çNDICE ESPACIAL (SINDEX)\n",
    "# ============================================================================\n",
    "\n",
    "# 1. Mapeo: Nombre amigable (para el c√≥digo) -> Nombre real de la capa en el GeoPackage\n",
    "SERVICE_LAYERS_MAP = {\n",
    "    \"salud\": \"establecimientos_salud\",\n",
    "    \"educacion_escolar\": \"establecimientos_educacion\",\n",
    "    \"educacion_superior\": \"establecimientos_educacion_superior\",\n",
    "    \"carabineros\": \"cuarteles_carabineros\",\n",
    "    \"bomberos\": \"companias_bomberos\",\n",
    "    \"metro_tren\": \"paradas_metro_tren\",\n",
    "    \"micro\": \"paradas_micro\",\n",
    "    \"deporte_infra\": \"infraestructura_deportiva\",\n",
    "    \"municipios\": \"municipios\",\n",
    "    \"ferias_libres\": \"ferias_libres\",\n",
    "    \"areas_verdes\": \"areas_verdes\",\n",
    "    \"iglesias\": \"osm_iglesias\",\n",
    "    \"museos\": \"osm_museos\",\n",
    "    \"supermercados\": \"osm_supermercados\",\n",
    "    \"almacenes_barrio\": \"osm_almacenes_barrio\",\n",
    "    \"bancos\": \"osm_bancos\",\n",
    "    \"malls\": \"osm_malls\",\n",
    "    \"bencineras\": \"osm_bencineras\",\n",
    "    \"estadios\": \"osm_estadios\",\n",
    "}\n",
    "\n",
    "# 2. Generar lista de categor√≠as objetivo autom√°ticamente\n",
    "# Toma todas las claves del diccionario anterior.\n",
    "TARGET_CATEGORIES = list(SERVICE_LAYERS_MAP.keys())\n",
    "\n",
    "print(f\"‚úÖ Configuraci√≥n de servicios actualizada.\")\n",
    "print(f\"üéØ Se calcular√° accesibilidad para {len(TARGET_CATEGORIES)} categor√≠as.\")\n",
    "print(f\"üìã Categor√≠as: {TARGET_CATEGORIES}\")\n",
    "\n",
    "def load_services_unified(target_cats):\n",
    "    gdfs = []\n",
    "    print(\"üì• Cargando capas de servicios...\")\n",
    "    for cat in target_cats:\n",
    "        layer = SERVICE_LAYERS_MAP.get(cat)\n",
    "        if not layer: continue\n",
    "        try:\n",
    "            # Cargar y asegurar proyecci√≥n Lat/Lon\n",
    "            gdf = gpd.read_file(RUTA_GPKG, layer=layer).to_crs(4326)\n",
    "            if gdf.empty: continue\n",
    "            \n",
    "            # Convertir pol√≠gonos a puntos para ruteo\n",
    "            gdf[\"geometry\"] = gdf.geometry.representative_point()\n",
    "            gdf[\"categoria\"] = cat\n",
    "            gdfs.append(gdf[[\"categoria\", \"geometry\"]])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error cargando {cat}: {e}\")\n",
    "            pass\n",
    "            \n",
    "    if not gdfs: return gpd.GeoDataFrame()\n",
    "    return pd.concat(gdfs, ignore_index=True)\n",
    "\n",
    "# 1. Cargar todo en un solo GeoDataFrame\n",
    "servicios = load_services_unified(TARGET_CATEGORIES)\n",
    "\n",
    "# 2. CREAR EL √çNDICE ESPACIAL (La clave de la velocidad)\n",
    "# Esto permite b√∫squedas instant√°neas en vez de medir distancia uno por uno\n",
    "if not servicios.empty:\n",
    "    servicios_sindex = servicios.sindex\n",
    "    print(f\"‚úÖ Servicios cargados: {len(servicios)} puntos.\")\n",
    "    print(\"‚úÖ √çndice espacial (R-tree) construido.\")\n",
    "else:\n",
    "    print(\"‚ùå No se cargaron servicios. Revisa la ruta del GPKG.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82c510-4819-4b26-8fe4-f1c7bd048304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 6: BUSCAR EL M√ÅS CERCANO Y CALCULAR TIEMPO\n",
    "# ============================================================================\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def get_min_travel_time(origin_lat, origin_lon, category, k=5):\n",
    "    # 1. Filtrar servicios\n",
    "    subset = servicios_gdf[servicios_gdf[\"categoria\"] == category].copy()\n",
    "    if subset.empty: return None\n",
    "    \n",
    "    # 2. Distancia euclidiana r√°pida para pre-filtrar\n",
    "    p_org = Point(origin_lon, origin_lat)\n",
    "    subset[\"dist\"] = subset.geometry.distance(p_org)\n",
    "    candidates = subset.nsmallest(k, \"dist\")\n",
    "    \n",
    "    min_time = float('inf')\n",
    "    found = False\n",
    "    \n",
    "    # 3. Consulta OTP real para los candidatos\n",
    "    for _, row in candidates.iterrows():\n",
    "        dest = row.geometry\n",
    "        # Aqu√≠ llama a la funci√≥n de la Celda 2 que arreglamos\n",
    "        t = otp_travel_time_minutes(origin_lat, origin_lon, dest.y, dest.x, WHEN_ISO)\n",
    "        \n",
    "        if t is not None:\n",
    "            found = True\n",
    "            if t < min_time:\n",
    "                min_time = t\n",
    "                \n",
    "    return min_time if found else None\n",
    "\n",
    "print(\"‚úÖ L√≥gica de accesibilidad lista.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff4e24-97db-4b08-95b7-5e32ea34ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 7: EJECUCI√ìN MASIVA\n",
    "# ============================================================================\n",
    "import time\n",
    "\n",
    "ACC_PATH = OUTPUTS_DIR / \"accesibilidad_servicios_otp.csv\"\n",
    "\n",
    "# Reanudar si existe\n",
    "if ACC_PATH.exists():\n",
    "    acc_df = pd.read_csv(ACC_PATH)\n",
    "    done = set(zip(acc_df[\"cod_comuna\"], acc_df[\"categoria\"]))\n",
    "    print(f\"üîÑ Reanudando: {len(acc_df)} datos previos.\")\n",
    "else:\n",
    "    acc_df = pd.DataFrame(columns=[\"cod_comuna\", \"comuna\", \"categoria\", \"minutos\"])\n",
    "    done = set()\n",
    "    print(\"üÜï Iniciando c√°lculo.\")\n",
    "\n",
    "# Usamos 'points' (definido en Celda 3)\n",
    "origins = points.to_dict(\"records\")\n",
    "buffer = []\n",
    "\n",
    "print(f\"üöÄ Procesando {len(origins)} comunas...\")\n",
    "\n",
    "for i, org in enumerate(origins):\n",
    "    cid = org[ID_COL]\n",
    "    cname = org[NAME_COL]\n",
    "    \n",
    "    print(f\"[{i+1}/{len(origins)}] {cname}...\", end=\"\\r\")\n",
    "    \n",
    "    for cat in TARGET_CATEGORIES:\n",
    "        if (cid, cat) in done: continue\n",
    "        \n",
    "        try:\n",
    "            val = get_min_travel_time(org[\"lat\"], org[\"lon\"], cat)\n",
    "            buffer.append({\"cod_comuna\": cid, \"comuna\": cname, \"categoria\": cat, \"minutos\": val})\n",
    "            done.add((cid, cat))\n",
    "        except Exception as e:\n",
    "            print(f\"Err: {e}\")\n",
    "\n",
    "    # Guardar cada 5 comunas\n",
    "    if len(buffer) >= 20:\n",
    "        acc_df = pd.concat([acc_df, pd.DataFrame(buffer)], ignore_index=True)\n",
    "        acc_df.to_csv(ACC_PATH, index=False)\n",
    "        buffer = []\n",
    "\n",
    "# Guardado final\n",
    "if buffer:\n",
    "    acc_df = pd.concat([acc_df, pd.DataFrame(buffer)], ignore_index=True)\n",
    "    acc_df.to_csv(ACC_PATH, index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 8: EXPORTAR PARA MACHINE LEARNING\n",
    "# ============================================================================\n",
    "\n",
    "df = pd.read_csv(ACC_PATH)\n",
    "\n",
    "# Pivotar para tener una columna por servicio\n",
    "df_pivot = df.pivot_table(index=[\"cod_comuna\", \"comuna\"], columns=\"categoria\", values=\"minutos\").reset_index()\n",
    "\n",
    "# Prefijo 'acc_' para diferenciar de los conteos\n",
    "cols_map = {c: f\"acc_{c}\" for c in TARGET_CATEGORIES}\n",
    "df_pivot = df_pivot.rename(columns=cols_map)\n",
    "\n",
    "# Guardar Parquet (M√°s r√°pido para Pandas) y CSV\n",
    "df_pivot.to_parquet(OUTPUTS_DIR / \"comunas_accessibility_otp.parquet\")\n",
    "df_pivot.to_csv(OUTPUTS_DIR / \"comunas_accessibility_otp.csv\", index=False)\n",
    "\n",
    "print(\"üì¶ Datos listos para Notebook 04:\")\n",
    "display(df_pivot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 9: FUNCIONES AVANZADAS (CACHE + SINDEX) - CORREGIDA\n",
    "# ============================================================================\n",
    "import hashlib\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Usa UTM 19S para medir metros reales en Santiago\n",
    "METRIC_CRS = \"EPSG:32719\"\n",
    "\n",
    "# Carpeta para guardar respuestas individuales de OTP\n",
    "OTP_CACHE_DIR = OUTPUTS_DIR / \"otp_cache_json\"\n",
    "OTP_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _otp_cache_key(o_lat, o_lon, d_lat, d_lon, when_iso):\n",
    "    s = f\"{o_lat:.6f},{o_lon:.6f}->{d_lat:.6f},{d_lon:.6f}|{when_iso}\"\n",
    "    return hashlib.md5(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def otp_travel_time_minutes_cached(o_lat, o_lon, d_lat, d_lon, when_iso):\n",
    "    \"\"\"\n",
    "    Consulta OTP con sistema de archivos cach√©.\n",
    "    \"\"\"\n",
    "    key = _otp_cache_key(o_lat, o_lon, d_lat, d_lon, when_iso)\n",
    "    path = OTP_CACHE_DIR / f\"{key}.json\"\n",
    "\n",
    "    # 1. Leer del disco\n",
    "    if path.exists():\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            return data[\"minutes\"]\n",
    "        except:\n",
    "            pass \n",
    "\n",
    "    # 2. Consultar OTP (funci√≥n de Celda 2)\n",
    "    minutes = otp_travel_time_minutes(o_lat, o_lon, d_lat, d_lon, when_iso)\n",
    "\n",
    "    # 3. Guardar en disco\n",
    "    if minutes is not None:\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\"minutes\": minutes}, f)\n",
    "\n",
    "    return minutes\n",
    "\n",
    "def query_point_access_otp_smart(lat, lon, categories, radius_m=5000, k=5):\n",
    "    \"\"\"\n",
    "    Usa el √≠ndice espacial para encontrar candidatos y luego OTP con cache.\n",
    "    \"\"\"\n",
    "    origin_wgs = Point(lon, lat)\n",
    "    \n",
    "    # --- FIX AQU√ç ---\n",
    "    # En lugar de extraer el objeto con .iloc[0], mantenemos la GeoSeries\n",
    "    # para poder usar .to_crs() y .buffer() en cadena.\n",
    "    \n",
    "    # 1. Crear GeoSeries del origen\n",
    "    gs_origin = gpd.GeoSeries([origin_wgs], crs=4326)\n",
    "    \n",
    "    # 2. Transformar a m√©trico -> Buffer -> Volver a WGS84\n",
    "    # Esto devuelve una GeoSeries con 1 pol√≠gono (el c√≠rculo transformado)\n",
    "    gs_buffer_wgs = gs_origin.to_crs(METRIC_CRS).buffer(radius_m).to_crs(4326)\n",
    "    \n",
    "    # 3. Obtener el Bounding Box (minx, miny, maxx, maxy) del pol√≠gono\n",
    "    # .total_bounds devuelve el array directamente\n",
    "    bbox = gs_buffer_wgs.total_bounds \n",
    "    # ----------------\n",
    "    \n",
    "    # 1. FILTRO R√ÅPIDO con Sindex (Intersecci√≥n con la caja del buffer)\n",
    "    possible_inds = list(servicios_sindex.intersection(bbox))\n",
    "    candidates = servicios.iloc[possible_inds].copy()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for cat in categories:\n",
    "        # Filtrar por categor√≠a\n",
    "        subset = candidates[candidates[\"categoria\"] == cat].copy()\n",
    "        if subset.empty:\n",
    "            results.append({\"categoria\": cat, \"tiempo_min\": None})\n",
    "            continue\n",
    "            \n",
    "        # Filtrar los k m√°s cercanos por distancia (pre-filtro)\n",
    "        subset[\"dist\"] = subset.geometry.distance(origin_wgs)\n",
    "        top_k = subset.nsmallest(k, \"dist\")\n",
    "        \n",
    "        min_minutes = float('inf')\n",
    "        found = False\n",
    "        \n",
    "        # 2. CONSULTA OTP REAL (con Cache)\n",
    "        for _, service in top_k.iterrows():\n",
    "            dest = service.geometry\n",
    "            t = otp_travel_time_minutes_cached(lat, lon, dest.y, dest.x, WHEN_ISO)\n",
    "            \n",
    "            if t is not None:\n",
    "                found = True\n",
    "                if t < min_minutes:\n",
    "                    min_minutes = t\n",
    "        \n",
    "        results.append({\n",
    "            \"categoria\": cat, \n",
    "            \"tiempo_min\": min_minutes if found else None\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"‚úÖ Funciones Smart corregidas (Fix to_crs).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c6370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 10: C√ÅLCULO DE ACCESIBILIDAD (VERSI√ìN FINAL CONECTADA A DOCKER)\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# --- CONFIGURACI√ìN CLAVE ---\n",
    "# 1. URL: Dentro de Docker, OTP se llama \"otp\", no \"localhost\"\n",
    "OTP_URL = \"http://otp:8080/otp/routers/default/plan\"\n",
    "\n",
    "# 2. FECHA: ¬°Ajusta esto a una fecha v√°lida de tu GTFS! (Ej: un martes h√°bil)\n",
    "FECHA_VIAJE = \"2023-11-15\"   \n",
    "HORA_VIAJE = \"08:00am\"\n",
    "\n",
    "# 3. PARAMETROS DE B√öSQUEDA\n",
    "RADIUS_M = 2000      # Radio de b√∫squeda de servicios (metros)\n",
    "K_NEIGHBORS = 1      # Solo el m√°s cercano para hacerlo r√°pido\n",
    "# ---------------------------\n",
    "\n",
    "print(f\"üîß Preparando geometr√≠as y conectando a {OTP_URL}...\")\n",
    "\n",
    "# 1. PREPARACI√ìN DE ENTORNOS (Proyecciones)\n",
    "# Transformamos a Metros (EPSG:3857) para medir distancias exactas\n",
    "comunas_m = gpd.GeoDataFrame(\n",
    "    points, \n",
    "    geometry=gpd.points_from_xy(points[\"lon\"], points[\"lat\"]), \n",
    "    crs=4326\n",
    ").to_crs(3857)\n",
    "\n",
    "servicios_m = servicios.to_crs(3857)\n",
    "servicios_sindex_m = servicios_m.sindex\n",
    "\n",
    "# Aseguramos IDs √∫nicos\n",
    "servicios = servicios.reset_index(drop=True)\n",
    "servicios_m[\"id_interno\"] = servicios_m.index\n",
    "\n",
    "# 2. FUNCI√ìN PARA CONSULTAR A OTP\n",
    "def get_otp_time(orig_lat, orig_lon, dest_lat, dest_lon, mode_str):\n",
    "    params = {\n",
    "        \"fromPlace\": f\"{orig_lat},{orig_lon}\",\n",
    "        \"toPlace\": f\"{dest_lat},{dest_lon}\",\n",
    "        \"time\": HORA_VIAJE,\n",
    "        \"date\": FECHA_VIAJE,\n",
    "        \"mode\": mode_str,\n",
    "        \"maxWalkDistance\": \"5000\",\n",
    "        \"arriveBy\": \"false\"\n",
    "    }\n",
    "    try:\n",
    "        # Timeout corto (2s) porque est√°n en la misma red local\n",
    "        response = requests.get(OTP_URL, params=params, timeout=2)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            # Navegamos el JSON para buscar la duraci√≥n\n",
    "            if 'plan' in data and 'itineraries' in data['plan'] and len(data['plan']['itineraries']) > 0:\n",
    "                duration_sec = data['plan']['itineraries'][0]['duration']\n",
    "                return duration_sec / 60.0 # Retornar en minutos\n",
    "            elif 'error' in data:\n",
    "                # Si OTP responde pero dice \"No trip found\"\n",
    "                return -1 \n",
    "        return None # Error de conexi√≥n o servidor\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# 3. BUCLE PRINCIPAL\n",
    "resultados = []\n",
    "print(f\"üöÄ Iniciando c√°lculo para {len(comunas_m)} or√≠genes...\")\n",
    "\n",
    "for idx, row_orig in comunas_m.iterrows():\n",
    "    # Datos del origen\n",
    "    cod_origen = points.iloc[idx][ID_COL] # Aseg√∫rate que ID_COL est√© definido antes\n",
    "    orig_lat = points.iloc[idx][\"lat\"]\n",
    "    orig_lon = points.iloc[idx][\"lon\"]\n",
    "    \n",
    "    # Imprimir progreso cada 10 filas para no saturar\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"   ... Procesando fila {idx}/{len(comunas_m)}\")\n",
    "\n",
    "    # FILTRO ESPACIAL: Primero buscamos lo que est√° cerca geom√©tricamente\n",
    "    centroide_m = row_orig.geometry\n",
    "    bbox = centroide_m.buffer(RADIUS_M).bounds\n",
    "    posibles_idxs = list(servicios_sindex_m.intersection(bbox))\n",
    "    \n",
    "    # Si no hay nada cerca, saltamos\n",
    "    if not posibles_idxs:\n",
    "        for cat in TARGET_CATEGORIES:\n",
    "            resultados.append({\"cod\": cod_origen, \"cat\": cat, \"minutos\": None, \"estado\": \"Fuera de rango\"})\n",
    "        continue\n",
    "\n",
    "    candidatos_m = servicios_m.iloc[posibles_idxs].copy()\n",
    "    \n",
    "    # Iteramos por cada categor√≠a de servicio (ej: Salud, Educaci√≥n, Paraderos)\n",
    "    for categoria in TARGET_CATEGORIES:\n",
    "        subset = candidatos_m[candidatos_m[\"categoria\"] == categoria]\n",
    "        \n",
    "        if subset.empty:\n",
    "            resultados.append({\"cod\": cod_origen, \"cat\": categoria, \"minutos\": None, \"estado\": \"Sin servicio cercano\"})\n",
    "            continue\n",
    "\n",
    "        # DEFINIR MODO DE TRANSPORTE\n",
    "        # Si buscamos paraderos, vamos caminando. Si buscamos hospitales, tomamos micro.\n",
    "        if categoria in [\"micro\", \"metro_tren\", \"paradas_micro\"]:\n",
    "            otp_mode = \"WALK\"\n",
    "        else:\n",
    "            otp_mode = \"WALK,TRANSIT\"\n",
    "\n",
    "        # Tomamos los K m√°s cercanos geom√©tricamente para preguntar a OTP\n",
    "        # (Esto ahorra consultas innecesarias a servicios lejanos)\n",
    "        subset[\"dist_geo\"] = subset.geometry.distance(centroide_m)\n",
    "        top_k = subset.sort_values(\"dist_geo\").head(K_NEIGHBORS)\n",
    "        \n",
    "        tiempos_otp = []\n",
    "        \n",
    "        for _, svc_row in top_k.iterrows():\n",
    "            # Volvemos a Lat/Lon para la API (usando el GeoDataFrame original 'servicios' que est√° en 4326)\n",
    "            dest_lat = servicios.iloc[svc_row.name].geometry.y\n",
    "            dest_lon = servicios.iloc[svc_row.name].geometry.x\n",
    "            \n",
    "            t = get_otp_time(orig_lat, orig_lon, dest_lat, dest_lon, otp_mode)\n",
    "            \n",
    "            if t is not None and t >= 0:\n",
    "                tiempos_otp.append(t)\n",
    "        \n",
    "        # Guardamos el mejor tiempo encontrado\n",
    "        if tiempos_otp:\n",
    "            resultados.append({\n",
    "                \"cod\": cod_origen, \n",
    "                \"cat\": categoria, \n",
    "                \"minutos\": min(tiempos_otp),\n",
    "                \"estado\": \"OK\"\n",
    "            })\n",
    "        else:\n",
    "            resultados.append({\n",
    "                \"cod\": cod_origen, \n",
    "                \"cat\": categoria, \n",
    "                \"minutos\": None, \n",
    "                \"estado\": \"Error OTP o Sin Ruta\"\n",
    "            })\n",
    "\n",
    "# 4. EXPORTAR RESULTADOS\n",
    "df_res = pd.DataFrame(resultados)\n",
    "print(\"\\n‚úÖ C√°lculo terminado.\")\n",
    "print(df_res.head())\n",
    "\n",
    "# Guardar\n",
    "# Aseg√∫rate que OUTPUTS_DIR est√© definido, si no, usa ruta relativa\n",
    "try:\n",
    "    df_res.to_csv(OUTPUTS_DIR / \"accesibilidad_otp_final.csv\", index=False)\n",
    "    print(f\"üìÅ Guardado en {OUTPUTS_DIR}\")\n",
    "except:\n",
    "    df_res.to_csv(\"accesibilidad_otp_final.csv\", index=False)\n",
    "    print(\"üìÅ Guardado en carpeta actual.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 11: PIVOT, LIMPIEZA Y RECUPERACI√ìN DE COMUNAS (FIX 52/52)\n",
    "# ============================================================================\n",
    "# Definir la variable que falta\n",
    "OUT_LONG = OUTPUTS_DIR / \"acc_long_partial.csv\"\n",
    "# 1. Cargar resultados parciales\n",
    "if not OUT_LONG.exists():\n",
    "    raise FileNotFoundError(\"‚ùå No se encontr√≥ el archivo 'acc_long_partial.csv'.\")\n",
    "\n",
    "df_long = pd.read_csv(OUT_LONG)\n",
    "\n",
    "# 2. Pivotar (Largo -> Ancho)\n",
    "acc_wide_raw = df_long.pivot_table(\n",
    "    index=[\"cod_comuna\"], # Usamos solo el c√≥digo como √≠ndice primario\n",
    "    columns=\"categoria\",\n",
    "    values=\"tiempo_min\",\n",
    "    aggfunc=\"min\"\n",
    ").reset_index()\n",
    "\n",
    "# 3. Renombrar columnas de categor√≠as\n",
    "acc_wide_raw.columns.name = None\n",
    "cat_cols = [c for c in acc_wide_raw.columns if c != \"cod_comuna\"]\n",
    "rename_map = {c: f\"acc_{c}\" for c in cat_cols}\n",
    "acc_wide_raw = acc_wide_raw.rename(columns=rename_map)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. CRUCIAL: RECUPERAR LAS COMUNAS PERDIDAS (LEFT JOIN)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Tomamos la tabla maestra de puntos (52 comunas) como base\n",
    "base_comunas = points[[ID_COL, NAME_COL]].copy()\n",
    "base_comunas = base_comunas.rename(columns={ID_COL: \"cod_comuna\", NAME_COL: \"comuna\"})\n",
    "\n",
    "# Pegamos los resultados. Las que no tengan datos quedar√°n como NaN autom√°gicamente.\n",
    "acc_final = base_comunas.merge(acc_wide_raw, on=\"cod_comuna\", how=\"left\")\n",
    "\n",
    "# 5. Guardar\n",
    "OUT_FINAL_PARQUET = OUTPUTS_DIR / \"comunas_accessibility_otp.parquet\"\n",
    "OUT_FINAL_CSV = OUTPUTS_DIR / \"comunas_accessibility_otp.csv\"\n",
    "\n",
    "acc_final.to_parquet(OUT_FINAL_PARQUET, index=False)\n",
    "acc_final.to_csv(OUT_FINAL_CSV, index=False)\n",
    "\n",
    "print(\"\\nüìä RESULTADO FINAL CORREGIDO:\")\n",
    "display(acc_final.head())\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"‚úÖ Archivos guardados en: {OUTPUTS_DIR}\")\n",
    "print(f\"üß© Dimensiones esperadas: (52, X) -> Dimensiones reales: {acc_final.shape}\")\n",
    "\n",
    "# Verificar si hay Nulos (Las comunas que recuperamos tendr√°n nulos)\n",
    "nulos = acc_final.isnull().sum()\n",
    "print(\"\\nüîç Conteo de comunas sin cobertura (NaN) por servicio:\")\n",
    "print(nulos[nulos > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa10551-0030-40f0-b91b-44a8bb5c8aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
